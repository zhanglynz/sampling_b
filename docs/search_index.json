[["index.html", "Uderstanding Survey Sampling Preface", " Uderstanding Survey Sampling Lingyun Zhang 2023-06-02 Preface How do you learn, or to be exact, how do you learn complex stuff? I guess that many different answers will come out, because we are all different in many aspects, such as culture background, knowledge level, and learning style etc. etc.. For myself, if I want to seriously learn some complex stuff, then I will write about it. Without doubts, sampling (or to be exact, survey sampling) is complex, and it is kind of boring, but it is important (for me, because I need it for my work, and for you the reasons may be different). So I have to learn and re-learn sampling, and this results in the current book. No matter what we want to study/learn, in my opinionprobably you agree with meunderstanding is the most important goal that we want to archive. For understanding, we must focus our attention on what, how and why, with unequal emphasis, depending on circumstances. A good starting point of learning about survey sampling is a couple of what questions: What is a sample? What is a good sample? We cover these questions especially the answers to them in Chapter 1. "],["sample.html", "1 Understanding Sample 1.1 What is a sample? 1.2 What is a good sample? 1.3 On sampling error", " 1 Understanding Sample 1.1 What is a sample? The question in the title is easy to answer: A sample is a subset of a population. Now, what is a population? Well, a population is defined in the planning stage of a study and is determined by study objectives.We can visualize a population using the following table: Member/Item ID Var\\(_1\\) Var\\(_2\\) \\(\\cdots\\) Var\\(_m\\) 1 2 \\(\\vdots\\) \\(N\\) So essentially a population is a list of members/items with associated characteristic variables that are of interest to the study. However, when it comes to the fine details in the population concept, things are kind of complicated. Following Lohr (2019), we distinguish three populations, namely, target population, sampling frame population and sampled population; see Figure 1. Figure 1: Three-population diagram. (Created by using R with some code borrowed from Peter Ellis, http://freerangestats.info/blog/2015/08/30/starting-in-datascience) Lets have an example. Target population: all private dwellings in New Zealand. Sampling frame population: address list purchased from New Zealand Post. Not eligible for survey: some non-private dwellings, e.g. a prison. Not included in sampling frame: some new private dwellings not included in NZ Post system. Not reachable: e.g. some private dwellings in certain islands are too costly to be visited 1.2 What is a good sample? According to Lohr (2019), A good sample will be representative in the sense that characteristics of interest in the population can be estimated from the sample with a known degree of accuracy. So a good sample should meet the following requirements: No serious over and under coverage issues, that is, the sampled population should be sufficiently close to the target population. No serious selection bias issue. Measurement and processing errors are negligible. If the soup (a metaphor for the population) is not well mixed before we take a sample from it, then the sample cannot be good. Even if the soup is well mixed, selection bias may still happen because of e.g. biased sampling frame or biased response. By a biased sampling frame, we mean for whatever reasons the sampling frame excludes a subset of the population, resulting discrepancy between it and the target population. Thats why we are concerned about coverage issuesunder coverage may cause serious selection bias. By biased response, we mean the responding sample is not representative. At survey operational level, we monitor response rate. If response rate is low, we worry that we may get biased response. If response rate is very low, say 20% or even lower, then the sample is quite likely suffering response bias. We omit details about measurement/processing errors here and refer readers to Lohr (2019), but we want to emphasize a point: Sampling survey is a very practical thing. 1.3 On sampling error In the last Section, we mentioned coverage issue, selection bias, measurement and processing issuesthese are all in the scope of non-sampling error. The flip side of the coin is sampling error, which is resulted from difference between a sample and the population in terms of characteristic variables. Sampling error is unavoidable! Lets have a toy example. The population is shown below. Unit_ID \\(Y\\) 1 6 2 7 3 8 4 1 5 5 We can list all the 10 possible samples of size 3 by collecting the IDs: \\[ \\{1, 2, 3\\}, \\ \\{1, 2, 4\\}, \\ \\{1, 2, 5\\}, \\ \\{1, 3, 4\\}, \\ \\{1, 3, 5\\} \\] \\[ \\{1, 4, 5\\}, \\ \\{2, 3, 4\\}, \\ \\{2, 3, 5\\}, \\ \\{2, 4, 5\\}, \\ \\{3, 4, 5\\} \\] The mean of \\(Y\\) (or population mean) is \\[ \\mu = \\frac{6+7+8+1+5}{5}=\\frac{27}{5}. \\] The 10 sample means are: 7, 14/3, 6, 5, 19/3, 4, 16/3, 20/3, 13/3, and 14/3, respectively. When we use one of the sample means to estimate the population mean, we expect that our estimate is away from the truththis shows sampling error. We often use mean square error (MSE) or standard mean square error (SMSE) to measure sampling error. \\[ \\hbox{MSE}=\\hbox{average of}\\ (\\hat{\\theta}-\\theta)^2\\ \\hbox{over all possible samples}, \\] where \\(\\theta\\) is the population parameter (e.g. population mean \\(\\mu\\)) and \\(\\hat{\\theta}\\) is a sample estimator (e.g. sample mean \\(\\hat{\\mu}\\)). \\[ \\hbox{SMSE}=\\sqrt{\\hbox{MSE}}. \\] It can be shown that \\[ \\hbox{MSE}= \\hbox{var}(\\hat{\\theta}) + \\left(\\hbox{bias}(\\hat{\\theta})\\right)^2, \\] where \\[ \\hbox{var}(\\hat{\\theta})=\\hbox{average of}\\ \\left(\\hat{\\theta}-\\hbox{avg}(\\hat{\\theta})\\right)^2\\ \\hbox{over all possible samples} \\] and \\[ \\hbox{bias}(\\hat{\\theta})=\\hbox{avg}(\\hat{\\theta})-\\theta, \\] in which \\[ \\hbox{avg}(\\hat{\\theta})=\\hbox{average of}\\ \\hat{\\theta}\\ \\hbox{over all possible samples.} \\] By the way, if \\[ \\hbox{bias}(\\hat{\\theta})=0 \\] then we say that \\(\\hat{\\theta}\\) is an unbiased estimator. For the toy example above, \\[ \\hbox{MSE}=\\frac{(7-27/5)^2+(14/3-27/5)^2+\\cdots+(14/3-27/5)^2}{10}=0.973, \\] and \\[ \\hbox{SMSE}=\\sqrt{\\hbox{MSE}}=0.987. \\] The MSE (or SMSE) is only useful in theoretical evaluation of a sampling method. In practice, people are concerned about \\(\\hbox{bias}(\\hat{\\theta})\\) and \\(\\hbox{var}(\\hat{\\theta})\\). So we must have good estimates of \\(\\hbox{bias}(\\hat{\\theta})\\) and \\(\\hbox{var}(\\hat{\\theta})\\). If we have sound reasons to believe that \\[ \\hbox{bias}(\\hat{\\theta})=0, \\] then we focus our attention on estimate of \\(\\hbox{var}(\\hat{\\theta})\\). A confidence interval can be constructed if \\(\\hat{\\theta}\\) value and estimate of \\(\\hbox{var}(\\hat{\\theta})\\) are ready. For the toy example, for each possible sample we calculate \\[ s^2=\\frac{1}{n-1}\\sum_{i=1}^n (y_i-\\bar{y})^2, \\] where \\(n=3\\), \\(\\{y_1, \\ldots, y_n\\}\\) consists of the sample and \\(\\bar{y}\\) is the sample mean (i.e. an observed \\(\\hat{\\mu}\\)). Let us use \\[ \\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{1}{n}s^2,} \\] where \\(N=5\\), to estimate \\(\\sqrt{\\hbox{var}(\\hat{\\mu})}\\); the estimate is denoted by \\(\\hat{\\sigma}\\). We set confidence interval using the following formula: \\[ (\\hat{\\mu} - 3\\times \\hat{\\sigma},\\ \\hat{\\mu} + 3\\times \\hat{\\sigma}); \\] we can find that nine out of the ten resulted confidence intervals do contain the truth \\(27/5\\). Table 1.1: Toy example: 10 possible samples and confidence intervals. y_bar s2 sigma lower_limit upper_limit indi 4.000000 7.000000 0.9660918 1.1017247 6.898275 1 4.333333 9.333333 1.1155467 0.9866932 7.679973 1 4.666667 12.333333 1.2823589 0.8195899 8.513744 1 4.666667 10.333333 1.1737878 1.1453033 8.188030 1 5.000000 13.000000 1.3165612 1.0503165 8.949684 1 5.333333 14.333333 1.3824294 1.1860451 9.480622 1 6.000000 1.000000 0.3651484 4.9045549 7.095445 1 6.333333 2.333333 0.5577734 4.6600133 8.006653 1 6.666667 2.333333 0.5577734 4.9933466 8.339987 1 7.000000 1.000000 0.3651484 5.9045549 8.095445 0 NB: Here is a quick explanation about nine out of the ten resulted confidence intervals do contain the truth. \\[ \\begin{array}{cl} &amp; \\hbox{Pr}(|\\hat{\\mu} - \\mu| &lt; 3\\hat{\\sigma})\\\\ \\approx &amp; \\hbox{Pr}(|t_2| &lt; 3)\\\\ = &amp; 0.905\\ \\hbox{(keeping three decimal places)} \\end{array} \\] where \\(t_2\\) is a random variable having \\(t\\) distribution with 2 degrees of freedom. "],["sampling.html", "2 Understanding Sampling 2.1 General ideas 2.2 Three theoretical principles 2.3 Sampling in practice 2.4 Exercises", " 2 Understanding Sampling 2.1 General ideas Throughout this chapter, sampling means probability sampling. Following (but not strictly) Tillé and Wilhelm (2017), the settings are as follows: The population is \\({\\cal P}=\\{1, 2, \\ldots, i, \\ldots, N\\}\\). A sample \\(s\\) is a subset of \\({\\cal P}\\). Note that \\(s\\) can be empty. There are \\(2^N\\) possible samples. Let the set of all the possible samples be denoted by \\(\\Omega\\). A sampling design specifies a probability distribution \\(p(\\cdot)\\) over \\(\\Omega\\) such that \\[ p(s)\\ge 0\\ \\hbox{and}\\ \\sum_{s\\in \\Omega} p(s)=1. \\] Define \\[ \\pi_i = \\hbox{the probability of selecting unit}\\ i \\] and for \\(i\\neq j\\) \\[ \\pi_{ij} = \\hbox{the probability that both units}\\ i\\ \\hbox{and}\\ j\\ \\hbox{are selected in the sample.} \\] Then, \\[ \\pi_i = \\sum_{i \\in s}p(s)\\ \\hbox{and}\\ \\pi_{ij}=\\sum_{\\{i,\\ j\\}\\subset s}p(s). \\] Examples of sampling designs: Simple random sampling: \\[ p(s)=\\left\\{ \\begin{array}{ll} {N \\choose n}^{-1}, &amp; \\hbox{if}\\ s\\in S_n,\\\\ 0, &amp; \\hbox{otherwise}, \\end{array} \\right. \\] where \\(S_n= \\{s\\in \\Omega|\\#s = n\\}\\) and \\(n\\) is the sample size. For this sampling design, \\[ \\pi_i = \\frac{n}{N}\\ \\hbox{and}\\ \\pi_{ij}= \\frac{n(n-1)}{N(N-1)}. \\] The essential in simple random sampling is that all possible subsets having \\(n\\) units are equally likely to be chosen. Stratified sampling: \\[ p(s)=\\left\\{ \\begin{array}{ll} \\prod_{h=1}^H{N_h \\choose n_h}^{-1}, &amp;\\hbox{if}\\ \\#(s\\bigcap {\\cal P}_h)=n_h\\ \\hbox{for}\\ h=1,\\ldots, H,\\\\ 0, &amp; \\hbox{otherwise}, \\end{array} \\right. \\] where the population \\({\\cal P}\\) is partitioned into \\(H\\) strata and \\(\\# {\\cal P}_h= N_h\\) for \\(h=1, \\ldots, H\\); \\(n_h\\) is the sample size for stratum \\({\\cal P}_h\\). For this sampling design, \\[ \\pi_i = \\frac{n_h}{N_h},\\ \\hbox{if}\\ i\\in {\\cal P}_h, \\] and \\[ \\pi_{ij}=\\left\\{ \\begin{array}{ll} \\frac{n_h(n_h-1)}{N_h(N_h-1)}, &amp; \\hbox{if}\\ i, j\\in {\\cal P}_h,\\\\ \\frac{n_gn_h}{N_gN_h}, &amp;\\hbox{if}\\ i \\in {\\cal P}_g,\\ j\\in {\\cal P}_h,\\ g\\neq h. \\end{array} \\right. \\] Bernoulli sampling: \\[ \\pi_i = p,\\ \\hbox{where}\\ 0 &lt; p &lt; 1,\\ \\hbox{for}\\ i=1, \\ldots, N; \\] sample \\(s\\) has units that are independently selected. Note that for Bernoulli sampling, sample size is a random variable and it follows Binomial\\((N, p)\\). The mean of the sample size is equal to \\(Np\\). Obviously, \\[\\pi_{i, j}=p^2\\ \\hbox{for}\\ i\\neq j.\\] All the possible samples in \\(\\Omega\\) can be classified into \\(N+1\\) classes using their cardinality (number of elements in a set), and we can check that \\[ \\begin{array}{cl} &amp;\\sum_{i=0,\\ \\#s = i}^Np(s)\\\\ =&amp;\\sum_{i=0}^N {N \\choose i}p^i(1-p)^{N-i}\\\\ =&amp;1. \\end{array} \\] Poisson sampling: The setting is the same as Bernoulli sampling except that the selection probabilities for units are not all equal. The distribution of the sample size is called Poisson binomial distribution. Conditional Poisson sampling: This design has prescribed unequal inclusion probabilities but results in samples with fixed sample size; see more details in Tillé and Wilhelm (2017). 2.2 Three theoretical principles Tillé and Wilhelm (2017) introduce three theoretical principles for sampling design. Randomization: a) make sure there are as many samples as possible, while meeting other constraints; b) select a sample at random. Overrepresentation: unequal inclusion probabilities often result in more efficient estimates, or in other words, we should preferentially select units where the dispersion is larger. Restriction: avoid bad samples, e.g. using auxiliary information to make sure the estimates from a sample approximately equal the known totals. That is, samples that either nonpractical or known to be inaccurate are avoided. We quote the following from Tillé and Wilhelm (2017). When auxiliary information is available, it is desired to include it in the sampling design in order to increase the precision of the estimates. A balanced sample is such that the estimated totals of the auxiliary variables are approximately equal to the true totals. At first glance, the principle of restriction seems to be in contradiction with the principle of randomization because it restricts the number of possible number of samples with nonnull probabilities. However, the possible number of samples is so large that, even with several constraints, the number of possible samples with nonnull probabilities can remain very large. 2.3 Sampling in practice 2.3.1 Systematic sampling As mentioned before, population and sample sizes are \\(N\\) and \\(n\\), respectively. The ideas in systematic sampling can be described as follows. The units in the population are put in some order, say, units \\(1,\\ 2,\\ \\ldots,\\ N\\). Randomly choose a unit as the start, e.g. start is unit \\(s\\), where \\(1\\le s\\le N\\). The jump number is \\(k\\), which is the integer that is the closest to \\(N/n\\). Then the \\(n\\) units \\[s;\\ (s+k)\\ \\hbox{mod}\\ N;\\ \\ldots;\\ (s+(n-1)k)\\ \\hbox{mod}\\ N\\] are chosen as the sample. NB: If the result of the mod operation is 0, then unit N is chosen into sample. R program: sys_sampling &lt;- function(N, n, start = NULL, indi_output = FALSE) {# a helper function round_helper &lt;- function(a) {L &lt;- floor(a) U &lt;- ceiling(a) d &lt;- c(a - L, U - a) if(d[1] &lt; d[2]) return(L) return(U) } # interval k &lt;- N / n k &lt;- round_helper(k) # start if(is.null(start)) start &lt;- ceiling(runif(1, 0, 1) * N) if(!start %in% 1L:N) stop(&quot;&#39;start&#39; must be integer between 1 and N!&quot;) # sample the_sample &lt;- (start + (0:(n - 1)) * k) %% N the_sample &lt;- ifelse(the_sample == 0L, N, the_sample) the_sample &lt;- sort(the_sample) # output if(indi_output) { temp &lt;- 1L:N output &lt;- as.integer(temp %in% the_sample) return(output) } return(the_sample) } Example: Suppose \\(N=10\\) and \\(n=3\\). We can show all the possible samples resulted from systematic sampling. library(dplyr) library(knitr) library(kableExtra) a_tbl &lt;- bind_cols(lapply(1:10, function(s) sys_sampling(N = 10, n = 3, start = s))) col_names &lt;- paste0(&quot;s_&quot;, 1:10) names(a_tbl) &lt;- col_names kable(a_tbl, &quot;html&quot;, align = rep(&#39;c&#39;, 10)) %&gt;% kable_styling(full_width = F) s_1 s_2 s_3 s_4 s_5 s_6 s_7 s_8 s_9 s_10 1 2 3 4 1 2 3 1 2 3 4 5 6 7 5 6 7 4 5 6 7 8 9 10 8 9 10 8 9 10 It is easy to notice that each unit has selection probability \\[ \\pi = \\frac{n}{N}=\\frac{3}{10}. \\] In our example, while simple random sampling results in 120 possible samples of size 3, systematic sample can result in only 10 possible samples of size. Judged by Randomization principle, systematic sampling is worse than simple random sampling. However, systematic sampling is often used by practitioners because of its simplicity. 2.3.2 Probability proportional to size In a sampling design, an important part is to determine selection probabilities, which accompany the units in the population. In terms of selection probabilities, we can distinguish two cases. Case 1: all the selection probabilities are equal. Case 2: the selection probabilities are not equal. Simple random sampling is an example of Case 1; probability proportional to size (PPS) is a method for creating unequal selection probabilities, i.e. its Case 2. With PPS, the selection probability of unit \\(i\\) is defined as \\[\\begin{equation} \\pi_i = n \\frac{Z_i}{\\sum_{i=1}^N Z_i},\\ \\text{for}\\ i=1, \\ldots, N, \\tag{2.1} \\end{equation}\\] where \\(n\\) and \\(N\\) are the sample size and population size, respectively, \\(Z_i\\) is the size/importance of unit \\(i\\). R program: pps_action &lt;- function(size_vec, the_n) {the_re &lt;- the_n * (size_vec / sum(size_vec)) the_n_fixed &lt;- the_n while(1) { bad_ones_index &lt;- which(the_re &gt; 1) good_ones_index &lt;- which(the_re &lt; 1) if(!length(bad_ones_index)) return(the_re) the_re[bad_ones_index] &lt;- 1 m &lt;- sum(the_re == 1) the_n &lt;- the_n_fixed - m the_re[good_ones_index] &lt;- the_n * (size_vec[good_ones_index] / sum(size_vec[good_ones_index])) } } Remarks: If some of \\(\\pi_i\\) resulted from (2.1) are greater than 1, then we set them as 1, and recalculate the rest \\(\\pi_i\\)s. The iteration process finishes until no \\(\\pi\\)s are greater than 1. See PPS action R program in the Appendix part. It is easy to see from (2.1) that \\[\\begin{equation} \\sum_{i=1}^N \\pi_i = n. \\tag{2.2} \\end{equation}\\] Actually, (2.2) is always hold if the sample size is fixed as \\(n\\); below is a quick proof: \\[\\begin{align} \\sum_{i=1}^N \\pi_i &amp;= \\sum_{i=1}^N\\sum_{i\\in s}p(s) \\notag\\\\ &amp;= n\\sum_{s\\in \\Omega}p(s) \\notag\\\\ &amp;= n\\times 1 \\notag\\\\ &amp;= n. \\notag \\end{align}\\] 2.4 Exercises 2.4.1 Unit selection probability in SRS Show that in simple random sampling, each unit has a selection probability of \\(n/N\\), where \\(n\\) and \\(N\\) are sample and population sizes, respectively. Hint: \\[ {N-1 \\choose n-1}/{N \\choose n}=\\frac{n}{N}. \\] 2.4.2 All possible samples for SRS with replacement Suppose the population is \\({\\cal P}=\\{1,\\ 2,\\ 3,\\ 4,\\ 5\\}\\). If we do SRS with replacement, where \\(n=3\\). Write an R program to list all possible samples. Note that if the selection resulted in, e.g. 1, 1, 1, then the sample is {1}i.e. we dont keep duplicated units. Hint: There are \\[ {5 \\choose 1}+{5 \\choose 2}+{5 \\choose 3} = 5 + 10 + 10 = 25 \\] possible samples. 2.4.3 An algorithm for drawing an SRS In Lohr (2010, 2021), one algorithm for drawing an SRS (Simple Random Sample without replacement) is as follows. Produce \\(N\\) random numbers from the Uniform(0, 1) distribution, and attach them to the \\(N\\) units in the sampling frame. Order the \\(N\\) units by the generated random numbers from the smallest to largest. The top \\(n\\) units are selected as the sample. Show that, indeed, this is simple random sampling without replacement. Hint: We can show that each of the \\({N \\choose n}\\) possible samples of size \\(n\\) has probability \\[ \\frac{n!(N-n)!}{N!}, \\] which is \\(1/{N \\choose n}\\), of being selected. "],["references.html", "References", " References Haziza, D. and Beaumont, J. (2017). Construction of Weights in Surveys: A Review. Statistical Science, Vol. 32, pp. 206-226. Tillé, Y. and Wilhelm, M. (2017). Probability Sampling Design: Principles for Choice of Design and Balancing. Statistical Science, Vol. 32, pp. 176-189. Lohr, S. (2010). Sampling: Design and Analysis. Second Edition. Lohr, S. (2021). Sampling: Design and Analysis. Third Edition. Chapman and Hall/CRC. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
